{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:bold; font-size:40px; color:green; line-height:1; margin:0px\">\n",
    "    Smart City Applications in Land Use and Transport (SCALUT)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfNSW GTFS-R Bus Vehicle Positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:bold; font-size:24px; color:Gold; line-height:1; margin:4px 0px\">\n",
    "    1.2A Transform .CSV Files by Agency (Daily to Monthly)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:bold; font-size:18px; color:tomato; line-height:1; margin:4px 0px\">\n",
    "    Housekeeping: Import Libraries/Packages\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "# import glob\n",
    "import time\n",
    "from zipfile import ZipFile\n",
    "# from numpy import loadtxt\n",
    "import geopandas as gpd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:bold; font-size:18px; color:tomato; line-height:1; margin:4px 0px\">\n",
    "    Specify Project Directory and Folders and Define Variables\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify the folder that stores the .PB.GZ files to be processed\n",
    "# FileTP = '200901_0000-2400'\n",
    "# FileTP = '201014_0000-2400'\n",
    "# FileTP = '201111_0000-2400'\n",
    "FileTP = 'Test_201014_0800-0805'\n",
    "DaysInMonth = 14\n",
    "\n",
    "# ## Specify the GTFS-R file prefix\n",
    "GTFS_VP_Prefix = 'GTFS_VP'\n",
    "\n",
    "## Specify the main directory that stores input and output folders\n",
    "DataDir = r'C:\\OneMetis Dropbox\\@One.IMS\\Datasets\\SCALUT_DW\\TfNSW_GTFS_Buses'\n",
    "\n",
    "## Specifiy the main folders that stores GTFS Static data\n",
    "FldRawStatic = '10_Raw_Static'\n",
    "FileIdStatic = '20200901190900'\n",
    "# FileIdStatic = '20201001191000'\n",
    "# FileIdStatic = '20201014201000'\n",
    "\n",
    "## Specify the main folders that store input and output data\n",
    "# FldRawPB = '10_Raw_PB'\n",
    "# FldRawCSVvp = '11_CSV_Raw_VP'\n",
    "FldTransVP = '12_CSV_Transformed_VP'\n",
    "FldTransVP_Agency = '12_CSV_Transformed_VP_byAgency'\n",
    "FldVP_Shp = '22_SHP_VP_GIS'\n",
    "FldVP_Shp_Agency = '22_SHP_VP_GIS_byAgency'\n",
    "\n",
    "## Specify the filename and location for the Routes List \n",
    "# FN_RoutesList = 'List_RouteShortNames_SydneyT80.txt'\n",
    "# FN_RoutesList = 'List_RouteShortNames_TheGong.txt'\n",
    "## OR\n",
    "Flt_Agency = 'Premier Illawarra'\n",
    "# Flt_Agency = 'Transit Systems'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Directory Path\n",
    "DirTransVP = DataDir + '/' + FldTransVP + '/' + FileTP\n",
    "if not os.path.exists(DirTransVP):\n",
    "    os.makedirs(DirTransVP)\n",
    "\n",
    "DirVP_Shp = DataDir + '/' + FldVP_Shp + '/' + FileTP\n",
    "if not os.path.exists(DirVP_Shp):\n",
    "    os.makedirs(DirVP_Shp)\n",
    "\n",
    "DirTransVP_Agency = DataDir + '/' + FldTransVP_Agency + '/' + FileTP\n",
    "if not os.path.exists(DirTransVP_Agency):\n",
    "    os.makedirs(DirTransVP_Agency)\n",
    "\n",
    "DirVP_Shp_Agency = DataDir + '/' + FldVP_Shp_Agency + '/' + FileTP\n",
    "if not os.path.exists(DirVP_Shp_Agency):\n",
    "    os.makedirs(DirVP_Shp_Agency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:bold; font-size:18px; color:tomato; line-height:1; margin:4px 0px\">\n",
    "    Define Functions\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "## Read Transformed VP CSV\n",
    "def Read_CSV_TransVP(f_TransVP):\n",
    "    df_TransVP = pd.read_csv(f_TransVP, \n",
    "                             sep=',', \n",
    "                             dtype={'id':'str',\n",
    "                                    'vehicle.trip.trip_id':'str',\n",
    "                                    'vehicle.trip.start_time':'str',\n",
    "                                    'vehicle.trip.start_date':'str',\n",
    "                                    'vehicle.trip.schedule_relationship':'str',\n",
    "                                    'vehicle.trip.route_id':'str',\n",
    "                                    'vehicle.position.latitude':'float',\n",
    "                                    'vehicle.position.longitude':'float',\n",
    "                                    'vehicle.position.bearing':'float',\n",
    "                                    'vehicle.position.speed':'float',\n",
    "                                    'vehicle.timestamp':'Int64',\n",
    "                                    'vehicle.congestion_level':'str',\n",
    "                                    'vehicle.vehicle.id':'str',\n",
    "#                                     'vehicle.vehicle.[transit_realtime.tfnsw_vehicle_descriptor].air_conditioned':'str', \n",
    "#                                     'vehicle.vehicle.[transit_realtime.tfnsw_vehicle_descriptor].wheelchair_accessible':'Int64',\n",
    "#                                     'vehicle.vehicle.[transit_realtime.tfnsw_vehicle_descriptor].vehicle_model':'str',\n",
    "#                                     'vehicle.vehicle.[transit_realtime.tfnsw_vehicle_descriptor].performing_prior_trip':'str',\n",
    "#                                     'vehicle.vehicle.[transit_realtime.tfnsw_vehicle_descriptor].special_vehicle_attributes':'Int64',\n",
    "                                    'vehicle.occupancy_status':'str',\n",
    "                                    'VPheaderTS':'str',\n",
    "                                    'vehicle.timestampUTC':'str',\n",
    "                                    'vehicle.trip.start_DateTimeUTC':'str'},\n",
    "#                              parse_dates=['vehicle.timestampUTC','vehicle.trip.start_DateTimeUTC']\n",
    "                            )\n",
    "    return(df_TransVP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:bold; font-size:18px; color:tomato; line-height:1; margin:4px 0px\">\n",
    "    Get Information from GTFS Static (Routes List by Agency)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Static Directory Path\n",
    "FileStaticZip = 'complete_gtfs_scheduled_data_' + FileIdStatic + '.zip'\n",
    "DirStaticZip = DataDir + '/' + FldRawStatic + '/' + FileStaticZip\n",
    "\n",
    "ZipStatic = ZipFile(DirStaticZip)\n",
    "df_StTimes = pd.read_csv(ZipStatic.open('stop_times.txt'),\n",
    "                         dtype={'trip_id':'str','arrival_time':'str','departure_time':'str','stop_id':'str',\n",
    "                                'stop_sequence':'Int32','stop_headsign':'str','pickup_type':'int','drop_off_type':'int',\n",
    "                                'shape_dist_traveled':'float','timepoint':'int','stop_note':'str'},\n",
    "                        )\n",
    "# df_StTimes.head(2)\n",
    "\n",
    "#############################################\n",
    "## Get List of Routes based on Agency Name ##\n",
    "df_Agency = pd.read_csv(ZipStatic.open('agency.txt'),dtype='unicode')\n",
    "df_Routes = pd.read_csv(ZipStatic.open('routes.txt'),dtype='unicode')\n",
    "df_Routes['RT_route_id'] = df_Routes['agency_id'] + '_' + df_Routes['route_short_name']\n",
    "\n",
    "df_RoutesAgency = pd.merge(df_Routes,\n",
    "                           df_Agency[['agency_id','agency_name']],\n",
    "                           how='left',\n",
    "                           suffixes=('','_Ag'),\n",
    "                           on=['agency_id'])\n",
    "\n",
    "df_RoutesAgency_Flt = df_RoutesAgency[df_RoutesAgency['agency_name'].isin([Flt_Agency])]\n",
    "# df_RoutesAgency_Flt.head(1)\n",
    "\n",
    "List_AgencyRtRoutes = df_RoutesAgency_Flt['RT_route_id']\n",
    "# List_AgencyRtRoutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:bold; font-size:18px; color:tomato; line-height:1; margin:4px 0px\">\n",
    "    FOR ARTEMIS: Create Daily Datasets by Agency and Combine into Monthly\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Record Start Time\n",
    "tStart = datetime.now()\n",
    "print('PROCESSING DATA FOR', FileTP, \"...\")\n",
    "print('Time Start:', tStart.isoformat(' ', 'seconds'))\n",
    "print('')\n",
    "\n",
    "####################################\n",
    "## Filter Daily Dataset by Agency ##\n",
    "\n",
    "## FOR LIST OF ROUTES BY AGENCY\n",
    "Agency = Flt_Agency\n",
    "Flt_Routes_Rt = List_AgencyRtRoutes\n",
    "\n",
    "## Define Output File Path by Agency\n",
    "PathTransVPAgency = DirTransVP_Agency + '/' + GTFS_VP_Prefix + '_' + FileTP + \"_\" + Agency + '.csv'\n",
    "PathTransVPshpAgency = DirVP_Shp_Agency + '/' + GTFS_VP_Prefix + '_' + FileTP + \"_\" + Agency + '.shp'\n",
    "\n",
    "## Check if file exists. Remove if exist.\n",
    "if os.path.exists(PathTransVPAgency):\n",
    "    os.remove(PathTransVPAgency)\n",
    "if os.path.exists(PathTransVPshpAgency):\n",
    "    os.remove(PathTransVPshpAgency)\n",
    "\n",
    "# df_ConVP = []\n",
    "for iDay in range(1, DaysInMonth+1):\n",
    "\n",
    "    ## Define Input File Path\n",
    "    PathTransVP = DirTransVP + '/' + GTFS_VP_Prefix + '_' + FileTP + 'd' + (str(iDay).zfill(2)) + '.csv'\n",
    "\n",
    "    if iDay == 1:\n",
    "        ## Call function to read Cln TU CSV files\n",
    "        df_ConVP = Read_CSV_TransVP(PathTransVP)\n",
    "        print(FileTP + 'd' + (str(iDay).zfill(2)), df_ConVP.shape)\n",
    "        ## Filter by Agency\n",
    "        df_ConVP_Flt = df_ConVP[df_ConVP['vehicle.trip.route_id'].isin(Flt_Routes_Rt)]\n",
    "        print(FileTP + 'd' + (str(iDay).zfill(2)) + ' for ' + Agency, df_ConVP_Flt.shape)\n",
    "    else:\n",
    "        df_X = Read_CSV_TransVP(PathTransVP)\n",
    "        print(FileTP + 'd' + (str(iDay).zfill(2)), df_X.shape)\n",
    "        ## Filter by Agency\n",
    "        df_X_Flt = df_X[df_X['vehicle.trip.route_id'].isin(Flt_Routes_Rt)]\n",
    "        print(FileTP + 'd' + (str(iDay).zfill(2)) + ' for ' + Agency, df_X_Flt.shape)\n",
    "        \n",
    "        df_ConVP_Flt = pd.concat([df_ConVP_Flt, df_X_Flt], ignore_index=True)\n",
    "\n",
    "## Export concatenated file to CSV\n",
    "df_ConVP_Flt.to_csv(PathTransVPAgency, index=False)\n",
    "\n",
    "## Convert df_ConVP_Flt into Spatial Information\n",
    "gdf_ConVP_Flt = gpd.GeoDataFrame(df_ConVP_Flt, \n",
    "                                 geometry=gpd.points_from_xy(df_ConVP_Flt['vehicle.position.longitude'], \n",
    "                                                             df_ConVP_Flt['vehicle.position.latitude']),\n",
    "                                 crs='EPSG:4326')\n",
    "## Export to SHP File\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "gdf_ConVP_Flt.to_file(PathTransVPshpAgency)\n",
    "warnings.resetwarnings()\n",
    "\n",
    "## Record End Time\n",
    "tEnd = datetime.now()\n",
    "print('')\n",
    "print(FileTP + ' for ' + Agency, df_ConVP_Flt.shape)\n",
    "print(iDay, 'Files Processed:', tEnd.isoformat(' ', 'seconds') + '; Time Spent:', tEnd-tStart)\n",
    "print('COMPLETED ON', datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to SCALUT TfNSW GTFS <b>[Table of Contents](SCALUT_TfNSW_GTFS_Analysis_TOC_v01.ipynb)</b>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "GTFS_r_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
