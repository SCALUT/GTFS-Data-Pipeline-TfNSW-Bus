{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:bold; font-size:40px; color:green; line-height:1; margin:0px\">\n",
    "    Smart City Applications in Land Use and Transport (SCALUT)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfNSW GTFS-R Bus Trip Update "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:bold; font-size:24px; color:Gold; line-height:1; margin:4px 0px\">\n",
    "    1.2 Transform .CSV Files\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:bold; font-size:18px; color:tomato; line-height:1; margin:4px 0px\">\n",
    "    Housekeeping: Import Libraries/Packages\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "from zipfile import ZipFile\n",
    "from GTFS_DPL_Funcs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:bold; font-size:18px; color:tomato; line-height:1; margin:4px 0px\">\n",
    "    Specify Project Directory and Folders and Define Variables\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specifiy the main directory that stores input and output folders\n",
    "DataDir = r'C:\\OneMetis Dropbox\\@One.IMS\\Datasets\\SCALUT_DW\\TfNSW_GTFS_Buses'\n",
    "\n",
    "## Specify the folder that stores the .PB.GZ files to be processed\n",
    "FileTP = 'Test_201014_0800-0805'\n",
    "DayInMonth = 14\n",
    "\n",
    "# ## Specify the GTFS-R file prefix\n",
    "GTFS_TU_Prefix = 'GTFS_TU'\n",
    "\n",
    "## Specifiy the main folders that stores input and output data\n",
    "# FldRawPB = '10_Raw_PB'\n",
    "FldRawCSVtu = '11_CSV_Raw_TU'\n",
    "FldTransTU = '12_CSV_Transformed_TU'\n",
    "FldClnTU = '13_CSV_Cleaned_Unique_TU'\n",
    "\n",
    "## Filter by Agency\n",
    "Flt_Agency = 'Premier Illawarra'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specifiy the main folders that stores GTFS Static data\n",
    "FldRawStatic = '10_Raw_Static'\n",
    "StaticIdLkUp = {\n",
    "#     'FileTP':'StaticId', \n",
    "    'Test_201014_0800-0805':'20201001191000', \n",
    "    '2020m06':'20200601190600', \n",
    "    '2020m07':'20200701190700', \n",
    "    '2020m08':'20200803190800', \n",
    "    '2020m09':'20200901190900', \n",
    "    '2020m10':'20201001191000', \n",
    "    '2020m11':'20201102191100', \n",
    "    '2020m12':'20201201191200', \n",
    "}\n",
    "if FileTP in StaticIdLkUp.keys():\n",
    "    FileIdStatic = StaticIdLkUp[FileTP]\n",
    "    print(FileIdStatic)\n",
    "else:\n",
    "    print(f\"ERROR: '{FileTP}' is not a key within the StaticIdLkUp.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Directory Path\n",
    "# DirRawPBtu = DataDir + '/' + FldRawPBtu + '/' + FileTP\n",
    "# DirRawPBtu = os.path.join(DataDir, FldRawPBtu, FileTP)\n",
    "\n",
    "# DirRawCSVtu = DataDir + '/' + FldRawCSVtu + '/' + FileTP\n",
    "DirRawCSVtu = os.path.join(DataDir, FldRawCSVtu, FileTP)\n",
    "if not os.path.exists(DirRawCSVtu):\n",
    "    os.makedirs(DirRawCSVtu)\n",
    "\n",
    "# DirTransTU = DataDir + '/' + FldTransTU + '/' + FileTP\n",
    "DirTransTU = os.path.join(DataDir, FldTransTU, FileTP)\n",
    "if not os.path.exists(DirTransTU):\n",
    "    os.makedirs(DirTransTU)\n",
    "\n",
    "# DirClnTU = DataDir + '/' + FldClnTU + '/' + FileTP\n",
    "DirClnTU = os.path.join(DataDir, FldClnTU, FileTP)\n",
    "if not os.path.exists(DirClnTU):\n",
    "    os.makedirs(DirClnTU)\n",
    "\n",
    "# File_RoutesList = DataDir + '/' + FN_RoutesList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:bold; font-size:18px; color:tomato; line-height:1; margin:4px 0px\">\n",
    "    Get Information from GTFS Static\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Static Directory Path\n",
    "FileStaticZip = 'complete_gtfs_scheduled_data_' + FileIdStatic + '.zip'\n",
    "DirStaticZip = DataDir + '/' + FldRawStatic + '/' + FileStaticZip\n",
    "\n",
    "ZipStatic = ZipFile(DirStaticZip)\n",
    "df_StTimes = pd.read_csv(ZipStatic.open('stop_times.txt'),\n",
    "                         dtype={'trip_id':'str','arrival_time':'str','departure_time':'str','stop_id':'str',\n",
    "                                'stop_sequence':'Int64','stop_headsign':'str','pickup_type':'int','drop_off_type':'int',\n",
    "                                'shape_dist_traveled':'float','timepoint':'int','stop_note':'str'},\n",
    "                        )\n",
    "# df_StTimes.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:bold; font-size:18px; color:tomato; line-height:1; margin:4px 0px\">\n",
    "    FOR ARTEMIS: Combine Complete Raw CSV Files\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Record Start Time\n",
    "tStart = datetime.now()\n",
    "print('PROCESSING DATA FOR', FileTP, \"...\")\n",
    "print('Time Start:', tStart.isoformat(' ', 'seconds'))\n",
    "       \n",
    "## Define File Path\n",
    "PathTransTUrtNoROT = DirTransTU + '/' + GTFS_TU_Prefix + '_' + FileTP + '_NoROT.csv'\n",
    "PathTransTUrtCln = DirClnTU + '/' + GTFS_TU_Prefix + '_' + FileTP + '_Cln.csv'\n",
    "\n",
    "## Check if file exists. Remove if exist.\n",
    "if os.path.exists(PathTransTUrtNoROT):\n",
    "    os.remove(PathTransTUrtNoROT)\n",
    "if os.path.exists(PathTransTUrtCln):\n",
    "    os.remove(PathTransTUrtCln)\n",
    "\n",
    "## Filter Route and Concatenate All CSV Files in Folder (add new column with Filename as trace)\n",
    "all_files = glob.glob(os.path.join(DirRawCSVtu, GTFS_TU_Prefix + '*.csv'))\n",
    "\n",
    "iFile = 0\n",
    "df_Con = []\n",
    "\n",
    "for f in all_files:\n",
    "\n",
    "    ## Count File\n",
    "    iFile = iFile + 1\n",
    "\n",
    "    ## Get FullFileName from Path\n",
    "##    FullFileName = f.split('/')[-1]     ## FOR LINUX COMPUTERS\n",
    "    FullFileName = f.split('\\\\')[-1]    ## FOR WINDOWS COMPUTERS\n",
    "    ## FileName exclude Extension\n",
    "    FNexExt = os.path.splitext(FullFileName)[0]\n",
    "\n",
    "    if iFile == 1:\n",
    "        ## Call function to read raw TU CSV files\n",
    "        df_Con = Read_CSV_Raw_TU(f)\n",
    "        ## Call function remove ROT records\n",
    "        df_Con_NoROT1 = Df_Remove_ROT(df_Con)\n",
    "    else:\n",
    "        ## Call function to read raw TU CSV files\n",
    "        df_X = Read_CSV_Raw_TU(f)\n",
    "        ## Call function remove ROT records\n",
    "        df_X_NoROT1 = Df_Remove_ROT(df_X)\n",
    "\n",
    "        ## Combine records from df_Con_Flt and df_X_Flt\n",
    "        df_Con_NoROT1 = pd.concat([df_Con_NoROT1, df_X_NoROT1], ignore_index=True)\n",
    "\n",
    "## Calculate Scheduled ArrivalTime\n",
    "df_Con_NoROT1 = Df_SchArrTime(df_Con_NoROT1)\n",
    "\n",
    "## Get Stop Sequence from GTFS Static\n",
    "df_Con_NoROT2 = Df_GetStaticStopSeq(df_Con_NoROT1, df_StTimes)\n",
    "\n",
    "## Get shape_dist_traveled from GTFS Static\n",
    "df_Con_NoROT3 = Df_GetStaticDist(df_Con_NoROT2, df_StTimes)\n",
    "\n",
    "## Flag Bad Observations\n",
    "df_Con_NoROT4 = Df_FlagBad(df_Con_NoROT3)\n",
    "\n",
    "## Export concatenated files to CSV\n",
    "df_Con_NoROT = df_Con_NoROT4\n",
    "df_Con_NoROT.to_csv(PathTransTUrtNoROT, index=False)\n",
    "\n",
    "## Clean Duplicate Data\n",
    "df_ConTU_Cln = Df_Remove_Duplicate(df_Con_NoROT)\n",
    "## Export Cleaned Data to CSV\n",
    "df_ConTU_Cln.to_csv(PathTransTUrtCln, index=False)\n",
    "\n",
    "## Record End Time\n",
    "tEnd = datetime.now()\n",
    "print(iFile, 'Files Processed:', tEnd.isoformat(' ', 'seconds') + '; Time Spent:', tEnd-tStart)\n",
    "print('After ROT Removed:', df_Con_NoROT.shape)\n",
    "print('Cleaned:', df_ConTU_Cln.shape)\n",
    "print('COMPLETED ON', datetime.now())\n",
    "print('Transformed file saved in:', PathTransTUrtNoROT)\n",
    "print('Cleaned file saved in:', PathTransTUrtCln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "GTFS_r_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
