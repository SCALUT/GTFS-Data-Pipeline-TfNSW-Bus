{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:bold; font-size:40px; color:green; line-height:1; margin:0px\">\n",
    "    Smart City Applications in Land Use and Transport (SCALUT)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfNSW GTFS-R Bus Trip Update "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:bold; font-size:24px; color:Gold; line-height:1; margin:4px 0px\">\n",
    "    1.2 Transform .CSV Files\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:bold; font-size:18px; color:tomato; line-height:1; margin:4px 0px\">\n",
    "    Housekeeping: Import Libraries/Packages\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "from zipfile import ZipFile\n",
    "from GTFS_DPL_Funcs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:bold; font-size:18px; color:tomato; line-height:1; margin:4px 0px\">\n",
    "    Specify Project Directory and Folders and Define Variables\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specifiy the main directory that stores input and output folders\n",
    "DataDir = r'C:\\OneMetis Dropbox\\@One.IMS\\Datasets\\SCALUT_DW\\TfNSW_GTFS_Buses'\n",
    "\n",
    "## Specify the folder that stores the .PB.GZ files to be processed\n",
    "FileTP = 'Test_201014_0800-0805'\n",
    "DayInMonth = 14\n",
    "\n",
    "# ## Specify the GTFS-R file prefix\n",
    "GTFS_TU_Prefix = 'GTFS_TU'\n",
    "\n",
    "## Specifiy the main folders that stores input and output data\n",
    "# FldRawPB = '10_Raw_PB'\n",
    "FldRawCSVtu = '11_CSV_Raw_TU'\n",
    "FldTransTU = '12_CSV_Transformed_TU'\n",
    "FldClnTU = '13_CSV_Cleaned_Unique_TU'\n",
    "\n",
    "## Filter by Agency\n",
    "Flt_Agency = 'Premier Illawarra'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20201001191000\n"
     ]
    }
   ],
   "source": [
    "## Specifiy the main folders that stores GTFS Static data\n",
    "FldRawStatic = '10_Raw_Static'\n",
    "StaticIdLkUp = {\n",
    "#     'FileTP':'StaticId', \n",
    "    'Test_201014_0800-0805':'20201001191000', \n",
    "    '2020m06':'20200601190600', \n",
    "    '2020m07':'20200701190700', \n",
    "    '2020m08':'20200803190800', \n",
    "    '2020m09':'20200901190900', \n",
    "    '2020m10':'20201001191000', \n",
    "    '2020m11':'20201102191100', \n",
    "    '2020m12':'20201201191200', \n",
    "}\n",
    "if FileTP in StaticIdLkUp.keys():\n",
    "    FileIdStatic = StaticIdLkUp[FileTP]\n",
    "    print(FileIdStatic)\n",
    "else:\n",
    "    print(f\"ERROR: '{FileTP}' is not a key within the StaticIdLkUp.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Directory Path\n",
    "# DirRawPBtu = DataDir + '/' + FldRawPBtu + '/' + FileTP\n",
    "# DirRawPBtu = os.path.join(DataDir, FldRawPBtu, FileTP)\n",
    "\n",
    "# DirRawCSVtu = DataDir + '/' + FldRawCSVtu + '/' + FileTP\n",
    "DirRawCSVtu = os.path.join(DataDir, FldRawCSVtu, FileTP)\n",
    "if not os.path.exists(DirRawCSVtu):\n",
    "    os.makedirs(DirRawCSVtu)\n",
    "\n",
    "# DirTransTU = DataDir + '/' + FldTransTU + '/' + FileTP\n",
    "DirTransTU = os.path.join(DataDir, FldTransTU, FileTP)\n",
    "if not os.path.exists(DirTransTU):\n",
    "    os.makedirs(DirTransTU)\n",
    "\n",
    "# DirClnTU = DataDir + '/' + FldClnTU + '/' + FileTP\n",
    "DirClnTU = os.path.join(DataDir, FldClnTU, FileTP)\n",
    "if not os.path.exists(DirClnTU):\n",
    "    os.makedirs(DirClnTU)\n",
    "\n",
    "# File_RoutesList = DataDir + '/' + FN_RoutesList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:bold; font-size:18px; color:tomato; line-height:1; margin:4px 0px\">\n",
    "    Define Functions\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #################################################\n",
    "# ## Read Raw TU CSV\n",
    "# def Read_CSV_Raw_TU(f):\n",
    "#     df_CSV_Raw_TU = pd.read_csv(f, sep=',', dtype={'id':'str',\n",
    "#                                                    'trip_update.trip.trip_id':'str',\n",
    "#                                                    'trip_update.trip.start_time':'str',\n",
    "#                                                    'trip_update.trip.start_date':'str',\n",
    "#                                                    'trip_update.trip.schedule_relationship':'str',\n",
    "#                                                    'trip_update.trip.route_id':'str',\n",
    "#                                                    'trip_update.vehicle.id':'str',\n",
    "#                                                    'trip_update.timestamp':'Int64',\n",
    "#                                                    'trip_update.stop_time_update.stop_sequence':'Int64',\n",
    "#                                                    'trip_update.stop_time_update.arrival.delay':'Int64',\n",
    "#                                                    'trip_update.stop_time_update.arrival.time':'Int64',\n",
    "#                                                    'trip_update.stop_time_update.departure.delay':'Int64',\n",
    "#                                                    'trip_update.stop_time_update.departure.time':'Int64',\n",
    "#                                                    'trip_update.stop_time_update.stop_id':'str',\n",
    "#                                                    'trip_update.stop_time_update.schedule_relationship':'str',\n",
    "#                                                    'TUheaderTS':'str',\n",
    "#                                                    'trip_update.timestampUTC':'str',\n",
    "#                                                    'trip_update.stop_time_update.arrival.timeUTC':'str',\n",
    "#                                                    'trip_update.stop_time_update.departure.timeUTC':'str',\n",
    "#                                                    'trip_update.trip.start_DateTimeUTC':'str'},\n",
    "#                                 parse_dates=['trip_update.trip.start_DateTimeUTC'])\n",
    "#     return(df_CSV_Raw_TU)\n",
    "\n",
    "# #################################################\n",
    "# ## Remove Redundant, Obsolete, Trivial Records\n",
    "# def Df_Remove_ROT(df):\n",
    "#     df_NoROT1 = df[\n",
    "#         (df['trip_update.trip.schedule_relationship'] != 'CANCELED') \n",
    "#         & (df['trip_update.trip.schedule_relationship'] != 'UNSCHEDULED') \n",
    "#         & (df['trip_update.stop_time_update.schedule_relationship'] != 'NO_DATA') \n",
    "#         & (df['trip_update.stop_time_update.arrival.time'] != 0)\n",
    "#     ]\n",
    "#     return(df_NoROT1)\n",
    "\n",
    "# #################################################\n",
    "# ## Calculate Scheduled ArrivalTime\n",
    "# def Df_SchArrTime(df_NoROT1):\n",
    "#     df_NoROT1['Rt.Scheduled_Arrival.Time'] = df_NoROT1['trip_update.stop_time_update.arrival.time'] - df_NoROT1['trip_update.stop_time_update.arrival.delay']\n",
    "#     df_NoROT1['Rt.Scheduled_Arrival.TimeUTC'] = pd.DatetimeIndex(\n",
    "#         pd.to_datetime(df_NoROT1['Rt.Scheduled_Arrival.Time'],unit='s'),tz='UTC').tz_convert(\n",
    "#         'Australia/Sydney').tz_localize(None)\n",
    "#     df_NoROT1['Rt.Scheduled_Arrival.TimeUTC'] = df_NoROT1['Rt.Scheduled_Arrival.TimeUTC'].dt.time\n",
    "#     df_NoROT1 = df_NoROT1.astype({'Rt.Scheduled_Arrival.TimeUTC':'str'})\n",
    "#     df_NoROT1['trip_update.trip.trip_id2'] = df_NoROT1['trip_update.trip.trip_id'].str.rsplit('_', 1).str.get(0)\n",
    "#     df_NoROT1['Rt.Scheduled_Arrival.TimeUTC2'] = df_NoROT1['Rt.Scheduled_Arrival.TimeUTC'].str.split(':').apply(lambda x:'%s:%s:%s' % (x[0] if int(x[0])>=4 else int(x[0])+24,x[1],x[2]))\n",
    "#     return(df_NoROT1)\n",
    "\n",
    "# #################################################\n",
    "# ## Get Stop Sequence from GTFS Static\n",
    "# def Df_GetStaticStopSeq(df_NoROT1):\n",
    "#     df_NoROT2 = pd.merge(df_NoROT1,\n",
    "#                          df_StTimes[['trip_id','arrival_time','stop_id','stop_sequence']],\n",
    "#                          how='left',\n",
    "#                          suffixes=('','_ST2'),\n",
    "#                          left_on=['trip_update.trip.trip_id2','trip_update.stop_time_update.stop_id','Rt.Scheduled_Arrival.TimeUTC2'],\n",
    "#                          right_on=['trip_id','stop_id','arrival_time'])\n",
    "#     df_NoROT2['stop_sequence'].fillna(df_NoROT2['trip_update.stop_time_update.stop_sequence'], inplace=True)\n",
    "\n",
    "#     ## Fill Empty Stop Sequence Using Existing Data\n",
    "#     df_NoROT2 = df_NoROT2.astype({'stop_sequence':'float'})\n",
    "#     df_NoROT2['stop_sequence'] = df_NoROT2.groupby(['trip_update.trip.route_id', \n",
    "#                                                     'trip_update.trip.trip_id', \n",
    "#                                                     'trip_update.trip.start_DateTimeUTC',\n",
    "#                                                     'trip_update.stop_time_update.stop_id'\n",
    "#                                                    ])['stop_sequence'].apply(lambda x:x.fillna(x.mean()))\n",
    "#     df_NoROT2['stop_sequence'] = df_NoROT2['stop_sequence'].round(0).astype('Int64')\n",
    "\n",
    "#     ## Drop Columns\n",
    "#     df_NoROT2 = df_NoROT2.drop(columns=['trip_id','arrival_time','stop_id'])\n",
    "#     return(df_NoROT2)\n",
    "\n",
    "# #################################################\n",
    "# ## Get shape_dist_traveled from GTFS Static\n",
    "# def Df_GetStaticDist(df_NoROT2):\n",
    "#     df_NoROT3 = pd.merge(df_NoROT2,\n",
    "#                          df_StTimes[['trip_id','stop_id','stop_sequence','shape_dist_traveled']],\n",
    "#                          how='left',\n",
    "#                          suffixes=('','_ST3'),\n",
    "#                          left_on=['trip_update.trip.trip_id2','trip_update.stop_time_update.stop_id','stop_sequence'],\n",
    "#                          right_on=['trip_id','stop_id','stop_sequence'])\n",
    "#     ## Drop Columns\n",
    "#     df_NoROT3 = df_NoROT3.drop(columns=['trip_id','stop_id'])\n",
    "#     return(df_NoROT3)\n",
    "\n",
    "# #################################################\n",
    "# ## Flag Bad Observations\n",
    "# def Df_FlagBad(df_NoROT4):\n",
    "#     df_NoROT4.sort_values(by=['trip_update.trip.route_id',\n",
    "#                               'trip_update.trip.trip_id',\n",
    "#                               'trip_update.trip.start_DateTimeUTC',\n",
    "#                               'stop_sequence',\n",
    "#                               'trip_update.timestamp'\n",
    "#                              ], inplace=True)\n",
    "\n",
    "#     df_NoROT4['Bad_Flag0'] = df_NoROT4.groupby(['trip_update.trip.route_id', \n",
    "#                                                 'trip_update.trip.trip_id', \n",
    "#                                                 'trip_update.trip.start_DateTimeUTC', \n",
    "#                                                 'stop_sequence'])['trip_update.timestamp'].diff().ge(240).fillna(0)*1\n",
    "\n",
    "#     df_NoROT4['Bad_Flag1'] = df_NoROT4.groupby(['trip_update.trip.route_id', \n",
    "#                                                 'trip_update.trip.trip_id', \n",
    "#                                                 'trip_update.trip.start_DateTimeUTC', \n",
    "#                                                 'stop_sequence'])['Bad_Flag0'].cumsum()\n",
    "#     return(df_NoROT4)\n",
    "\n",
    "# #################################################\n",
    "# ## Clean Duplicate Data\n",
    "# def Df_Remove_Duplicate(df_Dup):\n",
    "# #     df_Dup.sort_values(by=['trip_update.trip.route_id',\n",
    "# #                            'trip_update.trip.trip_id',\n",
    "# #                            'trip_update.trip.start_DateTimeUTC',\n",
    "# #                            'stop_sequence',\n",
    "# #                            'trip_update.timestamp'\n",
    "# #                           ], inplace=True)\n",
    "#     df_Dup2 = df_Dup[df_Dup['Bad_Flag1'] == 0]\n",
    "#     ## Drop Columns\n",
    "#     df_Dup2 = df_Dup2.drop(columns=['Bad_Flag0','Bad_Flag1'])\n",
    "#     df_Unique = df_Dup2.drop_duplicates(subset=['trip_update.trip.route_id',\n",
    "#                                                 'trip_update.trip.trip_id',\n",
    "#                                                 'trip_update.trip.start_DateTimeUTC',\n",
    "#                                                 'stop_sequence'\n",
    "#                                                ], keep='last')\n",
    "#     return(df_Unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:bold; font-size:18px; color:tomato; line-height:1; margin:4px 0px\">\n",
    "    Get Information from GTFS Static\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Static Directory Path\n",
    "FileStaticZip = 'complete_gtfs_scheduled_data_' + FileIdStatic + '.zip'\n",
    "DirStaticZip = DataDir + '/' + FldRawStatic + '/' + FileStaticZip\n",
    "\n",
    "ZipStatic = ZipFile(DirStaticZip)\n",
    "df_StTimes = pd.read_csv(ZipStatic.open('stop_times.txt'),\n",
    "                         dtype={'trip_id':'str','arrival_time':'str','departure_time':'str','stop_id':'str',\n",
    "                                'stop_sequence':'Int64','stop_headsign':'str','pickup_type':'int','drop_off_type':'int',\n",
    "                                'shape_dist_traveled':'float','timepoint':'int','stop_note':'str'},\n",
    "                        )\n",
    "# df_StTimes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:bold; font-size:18px; color:tomato; line-height:1; margin:4px 0px\">\n",
    "    FOR ARTEMIS: Combine Complete Raw CSV Files\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING DATA FOR Test_201014_0800-0805 ...\n",
      "Time Start: 2022-05-30 03:33:30\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_StTimes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5208/3594245576.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;31m## Get Stop Sequence from GTFS Static\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[0mdf_Con_NoROT2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDf_GetStaticStopSeq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_Con_NoROT1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;31m## Get shape_dist_traveled from GTFS Static\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\OneMetis Dropbox\\@One.Personal\\1001_Teck\\SmartieLab\\GitHub\\GTFS-Data-Pipeline-TfNSW-Bus\\GTFS_DPL\\GTFS_DPL_Funcs.py\u001b[0m in \u001b[0;36mDf_GetStaticStopSeq\u001b[1;34m(df_NoROT1)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mDf_GetStaticStopSeq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_NoROT1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     df_NoROT2 = pd.merge(df_NoROT1,\n\u001b[1;32m---> 56\u001b[1;33m                          \u001b[0mdf_StTimes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trip_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'arrival_time'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'stop_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'stop_sequence'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m                          \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m                          \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'_ST2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_StTimes' is not defined"
     ]
    }
   ],
   "source": [
    "## Record Start Time\n",
    "tStart = datetime.now()\n",
    "print('PROCESSING DATA FOR', FileTP, \"...\")\n",
    "print('Time Start:', tStart.isoformat(' ', 'seconds'))\n",
    "       \n",
    "## Define File Path\n",
    "PathTransTUrtNoROT = DirTransTU + '/' + GTFS_TU_Prefix + '_' + FileTP + '_NoROT.csv'\n",
    "PathTransTUrtCln = DirClnTU + '/' + GTFS_TU_Prefix + '_' + FileTP + '_Cln.csv'\n",
    "\n",
    "## Check if file exists. Remove if exist.\n",
    "if os.path.exists(PathTransTUrtNoROT):\n",
    "    os.remove(PathTransTUrtNoROT)\n",
    "if os.path.exists(PathTransTUrtCln):\n",
    "    os.remove(PathTransTUrtCln)\n",
    "\n",
    "## Filter Route and Concatenate All CSV Files in Folder (add new column with Filename as trace)\n",
    "all_files = glob.glob(os.path.join(DirRawCSVtu, GTFS_TU_Prefix + '*.csv'))\n",
    "\n",
    "iFile = 0\n",
    "df_Con = []\n",
    "\n",
    "for f in all_files:\n",
    "\n",
    "    ## Count File\n",
    "    iFile = iFile + 1\n",
    "\n",
    "    ## Get FullFileName from Path\n",
    "##    FullFileName = f.split('/')[-1]     ## FOR LINUX COMPUTERS\n",
    "    FullFileName = f.split('\\\\')[-1]    ## FOR WINDOWS COMPUTERS\n",
    "    ## FileName exclude Extension\n",
    "    FNexExt = os.path.splitext(FullFileName)[0]\n",
    "\n",
    "    if iFile == 1:\n",
    "        ## Call function to read raw TU CSV files\n",
    "        df_Con = Read_CSV_Raw_TU(f)\n",
    "        ## Call function remove ROT records\n",
    "        df_Con_NoROT1 = Df_Remove_ROT(df_Con)\n",
    "    else:\n",
    "        ## Call function to read raw TU CSV files\n",
    "        df_X = Read_CSV_Raw_TU(f)\n",
    "        ## Call function remove ROT records\n",
    "        df_X_NoROT1 = Df_Remove_ROT(df_X)\n",
    "\n",
    "        ## Combine records from df_Con_Flt and df_X_Flt\n",
    "        df_Con_NoROT1 = pd.concat([df_Con_NoROT1, df_X_NoROT1], ignore_index=True)\n",
    "\n",
    "## Calculate Scheduled ArrivalTime\n",
    "df_Con_NoROT1 = Df_SchArrTime(df_Con_NoROT1)\n",
    "\n",
    "## Get Stop Sequence from GTFS Static\n",
    "df_Con_NoROT2 = Df_GetStaticStopSeq(df_Con_NoROT1)\n",
    "\n",
    "## Get shape_dist_traveled from GTFS Static\n",
    "df_Con_NoROT3 = Df_GetStaticDist(df_Con_NoROT2)\n",
    "\n",
    "## Flag Bad Observations\n",
    "df_Con_NoROT4 = Df_FlagBad(df_Con_NoROT3)\n",
    "\n",
    "## Export concatenated files to CSV\n",
    "df_Con_NoROT = df_Con_NoROT4\n",
    "df_Con_NoROT.to_csv(PathTransTUrtNoROT, index=False)\n",
    "\n",
    "## Clean Duplicate Data\n",
    "df_ConTU_Cln = Df_Remove_Duplicate(df_Con_NoROT)\n",
    "## Export Cleaned Data to CSV\n",
    "df_ConTU_Cln.to_csv(PathTransTUrtCln, index=False)\n",
    "\n",
    "## Record End Time\n",
    "tEnd = datetime.now()\n",
    "print(iFile, 'Files Processed:', tEnd.isoformat(' ', 'seconds') + '; Time Spent:', tEnd-tStart)\n",
    "print('After ROT Removed:', df_Con_NoROT.shape)\n",
    "print('Cleaned:', df_ConTU_Cln.shape)\n",
    "print('COMPLETED ON', datetime.now())\n",
    "print('Transformed file saved in:', PathTransTUrtNoROT)\n",
    "print('Cleaned file saved in:', PathTransTUrtCln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "GTFS_r_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
